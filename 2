import pandas as pd
import numpy as np
from scipy.stats import gamma
import statsmodels.api as sm
from scipy.optimize import minimize

# SETUP

# Read in data
dat = pd.read_csv("~/Documents/PhD Toronto/PhD writing/Three estimates male fitness/Proc Roy Soc/Prepare to submit/Reviews Dec 21 2015/DRYAD data/DataFiles/AgeAtFlowering.csv")

# Remove the rows for which flowering data is missing due to natural or data error causes
dat = dat[(dat['MISSING'] == 0) & (dat['SURV_TO_FL'] == 1)]

# Install package 'bbmle' equivalent in Python using statsmodels and scipy

# NEGATIVE LOG LIKELIHOOD FUNCTION FOR DIFFERENCE BETWEEN GENERATIONS

# Create a new variable "AGE"
dat['AGE'] = dat['FL_DAY'] - dat['PDAY']  # Will get a bunch of NA's here- where flowering time is censored

def NLLgamma_pday2(y, condition1, condition2, condition3, x1, x2, intercept, b1, est_sd):
    est_mean = intercept + (b1 * x1)
    
    prob_vect = np.where(condition1 == 1, (gamma.sf(36, a=(est_mean**2)/(est_sd**2), scale=(est_sd**2)/est_mean) - gamma.sf(40, a=(est_mean**2)/(est_sd**2), scale=(est_sd**2)/est_mean)),
                np.where(condition2 == 1, (gamma.sf(45, a=(est_mean**2)/(est_sd**2), scale=(est_sd**2)/est_mean) - gamma.sf(48, a=(est_mean**2)/(est_sd**2), scale=(est_sd**2)/est_mean)),
                np.where(condition3 == 1, (gamma.sf(49-x2, a=(est_mean**2)/(est_sd**2), scale=(est_sd**2)/est_mean) - gamma.sf(52-x2, a=(est_mean**2)/(est_sd**2), scale=(est_sd**2)/est_mean)),
                gamma.pdf(y, a=(est_mean**2)/(est_sd**2), scale=(est_sd**2)/est_mean))))
    
    return -1 * np.sum(np.log(prob_vect))

# Brief explanation of the function above
# "censor 1" means dry buds 41 == 1
# Censor 2 means dry buds 42 == 1
# Censor 3 means herb_49 == 1
# In each of these three cases, flowering time can be approximated by subtracting the best estimate flowering time range from the planting date of a seed (either 0 or 10).
# In all other cases, age at flowering (flowering day - planting day) was directly observed.
# The distribution of ages at flowering is approximated by a gamma distribution. I previously determined that this was a better fit to the data than a gaussian distribution.
# Gamma is defined by shape and scale parameters, which can in turn be expressed as functions of the mean and standard deviation.
# The NLL function is used to find the mean and standard deviation that best describe the observed data. The mean is allowed (but not forced) to vary between parental and offspring generations. The difference between generations is the response to selection.

# BUILD TABLE TO HOLD RESULTS
result = pd.DataFrame(columns=["Pop", "Samp", "Parameter", "Est", "SE", "LCI", "UCI"])

# Loop through populations & through offspring samples
populations = [1, 3, 5]  # Note that pop 1 = uncorrelated treatment; pop 3 = negative correlation; pop 5 = positive correlation
os_sample = ["prop", "even"]

for p in populations:
    for s in os_sample:
        temp = pd.DataFrame(columns=result.columns)
        temp['Pop'] = [p] * 3
        temp['Samp'] = [s] * 3
        temp['Parameter'] = ["Intercept", "b.offspring", "Est.sd"]

        pop = dat[dat['POPULATION'] == p]
        pop['OFFSPRING'] = np.where(pop['PARENT'] == 1, 0, 1)  # Reverse the coding for PARENT column so that parents are scored as '0' (and become the 'intercept' of the model for the mean), and offspring as 1 (and become the value associated with b1 in the model.)

        # Reduce dataset to proportional or even sample
        if s == "prop":
            pop = pop[~((pop['OS_EVEN'] == 1) & (pop['OS_PROP'] == 0))]
        else:
            pop = pop[~((pop['OS_EVEN'] == 0) & (pop['OS_PROP'] == 1))]

        # Fit the model using maximum likelihood estimation
        fit = minimize(NLLgamma_pday2, x0=[30, 0, 3], args=(pop['AGE'], pop['DRY_BUDS41'], pop['DRY_BUDS42'], pop['HERB_49'], pop['OFFSPRING'], pop['PDAY']), bounds=[(0, None), (-np.inf, np.inf), (0, None)], method='L-BFGS-B')

        # Extract estimates and standard errors
        temp['Est'] = np.round(fit.x, 2)
        temp['SE'] = np.round(np.sqrt(np.diag(fit.hess_inv.todense())), 2)

        # Profile likelihood to get confidence intervals
        prof = sm.tools.profile(fit)
        ci = sm.stats.conf_int(prof)

        temp['LCI'] = ci[:, 0]
        temp['UCI'] = ci[:, 1]

        result = pd.concat([result, temp], ignore_index=True)

# Coefficient "b.offspring" is the response to selection on age at flowering (units = days)
print(result)
